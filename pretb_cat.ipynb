{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa2c5df0",
   "metadata": {},
   "source": [
    "# Algorithm Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8419355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32b343f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "random_state = 6\n",
    "test_size = 0.2\n",
    "db_file = 'data/pretb_cat_final.csv'\n",
    "split_date = '2020-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2164bc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into data frame\n",
    "df = pd.read_csv(db_file,\n",
    "                 encoding=\"utf-8\",\n",
    "                 sep=\";\",\n",
    "                 header=0\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac9f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include only most recent tumor boards to reflect current tumorboard guidelines\n",
    "df['pretb_date'] = pd.to_datetime(df['pretb_date'], dayfirst=True)\n",
    "df = df.loc[df['pretb_date'] > split_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7ba2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e798340",
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_enc = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55d5b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables from text to numerical\n",
    "df['dre'] = ord_enc.fit_transform(df[['dre']])\n",
    "df['site'] = ord_enc.fit_transform(df[['site']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f006b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and outcomes\n",
    "feature_cols = ['age', \"psa\", \"dre\", 'site', \"isup\", \"cylinder_pos\", \"cylinder_total\", 'ht', 'dm', 'cad', 'bmi', 'preop']\n",
    "outcome_cols = [\"psma\", 'conv_staging', \"as\", 'rp_rt']\n",
    "X = df[feature_cols]\n",
    "y = df[outcome_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e9102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stratification of train test split according to outcomes with lowest numbers\n",
    "y_strat = y.loc[:, ['psma', 'as']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32a94fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=y_strat, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7fd75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save train and test data to csv for descriptive statistics\n",
    "X_train.to_csv('data/X_train.csv', index=False)\n",
    "X_test.to_csv('data/X_test.csv', index=False)\n",
    "y_train.to_csv('data/y_train.csv', index=False)\n",
    "y_test.to_csv('data/y_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf7b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values for continuous variables using median of training set\n",
    "imp1 = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "# Fit and transform on training set\n",
    "X_train['psa'] = imp1.fit_transform(X_train[['psa']])\n",
    "X_train['cylinder_pos'] = imp1.fit_transform(X_train[['cylinder_pos']])\n",
    "X_train['cylinder_total'] = imp1.fit_transform(X_train[['cylinder_total']])\n",
    "\n",
    "# Transform on test set\n",
    "X_test['psa'] = imp1.fit_transform(X_test[['psa']])\n",
    "X_test['cylinder_pos'] = imp1.fit_transform(X_test[['cylinder_pos']])\n",
    "X_test['cylinder_total'] = imp1.fit_transform(X_test[['cylinder_total']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b2170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values for categorial variables using most frequent in training set\n",
    "imp2 = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "# Fit and transform on training set\n",
    "X_train['isup'] = imp2.fit_transform(X_train[['isup']])\n",
    "X_train['site'] = imp2.fit_transform(X_train[['site']])\n",
    "X_train['dre'] = imp2.fit_transform(X_train[['dre']])\n",
    "\n",
    "# Transform on test set\n",
    "X_test['isup'] = imp2.fit_transform(X_test[['isup']])\n",
    "X_test['site'] = imp2.fit_transform(X_test[['site']])\n",
    "X_test['dre'] = imp2.fit_transform(X_test[['dre']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47b6a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train DecisionTree model\n",
    "dt_clf = OneVsRestClassifier(DecisionTreeClassifier(max_leaf_nodes=50, criterion=\"entropy\", random_state=random_state))\n",
    "dt_clf.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "y_pred = dt_clf.predict(X_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e572d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e79b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Accuracy : \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4011afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=outcome_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c46fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train RandomForest model\n",
    "rnd_clf = OneVsRestClassifier(RandomForestClassifier(n_estimators=100, criterion=\"entropy\", random_state=random_state))\n",
    "\n",
    "rnd_clf.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "\n",
    "y_pred = rnd_clf.predict(X_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2927be28",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd66e7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Accuracy : \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810b5db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=outcome_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3298d184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train KNN model\n",
    "knn_clf = OneVsRestClassifier(KNeighborsClassifier())\n",
    "\n",
    "knn_clf.fit(X_train.to_numpy(), y_train.to_numpy())\n",
    "\n",
    "y_pred = knn_clf.predict(X_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fff995",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407c998a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Accuracy : \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3d849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=outcome_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b87c196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test sample for model out evaluation\n",
    "test_sample = X_test.iloc[13, :].to_frame().transpose()\n",
    "test_output = rnd_clf.predict(test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e21bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_output(output):\n",
    "    psma_string = \"Bevorzugt PSMA-PET-CT. Alternativ Ganzkörperknochenszintigraphie und CT-Abdomen und Becken. \"\n",
    "    ct_scintigraphy_string = \"Ganzkörperknochenszintigraphie und CT-Abdomen und Becken.\"\n",
    "    as_string = \"Der Patient erfüllt die Kriterien für eine aktive Überwachung. Falls eine definitive Therapie erwünscht ist, Angebot einer radikalen Prostatektomie oder alternativ perkutane Strahlentherapie.\"\n",
    "    rp_rt_string = \"Indikation zur radikalen Prostatektomie. Alternativ perkutane Strahlentherapie.\"\n",
    "    \n",
    "    output_string = \"\"\n",
    "    \n",
    "    if output[0] == 1:\n",
    "        # PSMA\n",
    "        output_string += psma_string\n",
    "\n",
    "    if output[1] == 1:\n",
    "        # CT and bone scintigraphy\n",
    "        if output[0] == 0:\n",
    "            output_string += ct_scintigraphy_string\n",
    "            \n",
    "    if output[2] == 1:\n",
    "        # Active Surveillance\n",
    "        output_string += as_string\n",
    "\n",
    "    if output[3] == 1:\n",
    "        # Radical prostatectomy and radiation therapy\n",
    "        if output[2] == 0:\n",
    "            output_string += rp_rt_string\n",
    "    \n",
    "    return output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b5fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = test_output[0]\n",
    "output_string = convert_output(test_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ea7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_output)\n",
    "print(output_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0a6408",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ab7570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1c7c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bootstrap(X, y, model, metric, n_iterations):\n",
    "    accuracy_list = []\n",
    "    for i in tqdm(range(n_iterations)):\n",
    "        X_bs, y_bs = resample(X, y, replace=True)\n",
    "        # make predictions\n",
    "        y_hat = model.predict(X_bs)\n",
    "        # evaluate model\n",
    "        accuracy = metric(y_bs, y_hat)\n",
    "        accuracy_list.append(accuracy)\n",
    "    return accuracy_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b11d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_by_cat(X, y, model, metric, index, n_iterations):\n",
    "    metric_list = []\n",
    "    for i in tqdm(range(n_iterations)):\n",
    "        X_bs, y_bs = resample(X, y, replace=True)\n",
    "        # make predictions\n",
    "        y_hat = pd.DataFrame(model.predict(X_bs))\n",
    "        # evaluate model\n",
    "        metric_value = metric(y_bs.iloc[:, index], y_hat.iloc[:, index])\n",
    "        metric_list.append(metric_value)\n",
    "    return metric_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c32390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ci(metric):\n",
    "    ci_metrics = []\n",
    "    # get median\n",
    "    median = np.percentile(metric, 50)\n",
    "\n",
    "    # get 95% confidence interval\n",
    "    alpha = 100-95\n",
    "    lower_ci = np.percentile(metric, alpha/2)\n",
    "    upper_ci = np.percentile(metric, 100-alpha/2)\n",
    "\n",
    "    ci_metrics = [median, lower_ci, upper_ci]\n",
    "    return ci_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e7900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(X, y, model, n_iterations):\n",
    "    # Calculate metrics with bootstrapping\n",
    "    accuracy = bootstrap(X, y, model, accuracy_score, n_iterations)\n",
    "\n",
    "    precision_psma = bootstrap_by_cat(X, y, model, precision_score, 0, n_iterations)\n",
    "    precision_conv_staging = bootstrap_by_cat(X, y, model, precision_score, 1, n_iterations)\n",
    "    precision_as = bootstrap_by_cat(X, y, model, precision_score, 2, n_iterations)\n",
    "    precision_rp_rt = bootstrap_by_cat(X, y, model, precision_score, 3, n_iterations)\n",
    "\n",
    "    recall_psma = bootstrap_by_cat(X, y, model, recall_score, 0, n_iterations)\n",
    "    recall_conv_staging = bootstrap_by_cat(X, y, model, recall_score, 1, n_iterations)\n",
    "    recall_as = bootstrap_by_cat(X, y, model, recall_score, 2, n_iterations)\n",
    "    recall_rp_rt = bootstrap_by_cat(X, y, model, recall_score, 3, n_iterations)\n",
    "\n",
    "    f1_psma = bootstrap_by_cat(X, y, model, f1_score, 0, n_iterations)\n",
    "    f1_conv_staging = bootstrap_by_cat(X, y, model, f1_score, 1, n_iterations)\n",
    "    f1_as = bootstrap_by_cat(X, y, model, f1_score, 2, n_iterations)\n",
    "    f1_rp_rt = bootstrap_by_cat(X, y, model, f1_score, 3, n_iterations)\n",
    "\n",
    "    # Prepare results for table\n",
    "    result_columns = ['precision (median)', 'precision (lower 95% CI)', 'precision (upper 95% CI)',\n",
    "                    'recall (median)', 'recall (lower 95% CI)', 'recall (upper 95% CI)',\n",
    "                    'f1_score (median)', 'f1_score (lower 95% CI)', 'f1_score (upper 95% CI)'          \n",
    "                    ]\n",
    "\n",
    "    index_rows = ['PSMA', 'conventional imaging', 'active surveillance', 'radical therapy']\n",
    "\n",
    "    psma_results = np.array([get_ci(precision_psma), get_ci(recall_psma), get_ci(f1_psma)]).ravel()\n",
    "    conv_staging_results = np.array([get_ci(precision_conv_staging), get_ci(recall_conv_staging), get_ci(f1_conv_staging)]).ravel()\n",
    "    as_results = np.array([get_ci(precision_as), get_ci(recall_as), get_ci(f1_as)]).ravel()\n",
    "    rp_rt_results = np.array([get_ci(precision_rp_rt), get_ci(recall_rp_rt), get_ci(f1_rp_rt)]).ravel()\n",
    "\n",
    "    # Create and show results table\n",
    "    result_table = pd.DataFrame([psma_results, conv_staging_results, as_results, rp_rt_results], columns=result_columns, index=index_rows)\n",
    "    return result_table\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fcd8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_acc = bootstrap(X_test.values, y_test.values, dt_clf, accuracy_score, 1000)\n",
    "dt_acc_ci = get_ci(dt_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d29164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Decision Tree Classifier Accuracy:')\n",
    "pd.DataFrame(np.array(dt_acc_ci).reshape(1,3), columns=['median', 'lower 95% CI', 'upper 95% CI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b21c19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show results for decision tree classifier\n",
    "show_results(X_test, y_test, dt_clf, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87df59a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_acc = bootstrap(X_test, y_test, rnd_clf, accuracy_score, 1000)\n",
    "rnd_acc_ci = get_ci(rnd_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aec4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Random Forest Classifier Accuracy:')\n",
    "pd.DataFrame(np.array(rnd_acc_ci).reshape(1,3), columns=['median', 'lower 95% CI', 'upper 95% CI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59a7644",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(X_test, y_test, rnd_clf, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68325b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_acc = bootstrap(X_test, y_test, knn_clf, accuracy_score, 1000)\n",
    "knn_acc_ci = get_ci(knn_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2c4e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('K-Nearest Neighbour Classifier Accuracy:')\n",
    "pd.DataFrame(np.array(knn_acc_ci).reshape(1,3), columns=['median', 'lower 95% CI', 'upper 95% CI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb9ee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(X_test, y_test, knn_clf, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7676f6e0",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7688f643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_curve(model, model_name, X_test, y_test):\n",
    "    y_score = model.predict_proba(X_test.to_numpy())\n",
    "    \n",
    "    # Calculate precision-recall curve\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "    classes = ['PSMA-PET', 'Conventional imaging', 'Active Surveillance', 'Local therapy']\n",
    "    n_classes = y_test.shape[1]\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        precision[i], recall[i], _ = precision_recall_curve(y_test.to_numpy()[:, i], y_score[:, i])\n",
    "        average_precision[i] = average_precision_score(y_test.to_numpy()[:, i], y_score[:, i])\n",
    "\n",
    "    # Plot precision-recall curve\n",
    "    plt.figure()\n",
    "    colors = ['blue', 'red', 'green', 'orange']\n",
    "    for i, color in zip(range(n_classes), colors):\n",
    "        plt.plot(recall[i], precision[i], color=color, lw=2, linestyle='--',\n",
    "                label='{0} (average precision = {1:0.2f})'\n",
    "                ''.format(classes[i], average_precision[i]))\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall curve for {}'.format(model_name))\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d73f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall_curve(dt_clf, 'Decision Tree', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6f8130",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall_curve(rnd_clf, 'Random Forest', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c307cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall_curve(knn_clf, 'K-Nearest Neighbour', X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f32f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names =['Age',\n",
    "                 'PSA',\n",
    "                 'DRE',\n",
    "                 'Site',\n",
    "                 'ISUP\\ncategory',\n",
    "                 'Cylinder\\npositive',\n",
    "                 'Cylinder\\ntotal',\n",
    "                 'Hypertension',\n",
    "                 'Diabetes\\nmellitus',\n",
    "                 'CAD',\n",
    "                 'BMI',\n",
    "                 'Preop'\n",
    "                 ]\n",
    "\n",
    "label_names = ['PSMA-PET',\n",
    "               'Conventional imaging',\n",
    "               'Active Surveillance',\n",
    "               'Local therapy'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792b03bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importances for each label\n",
    "for i, estimator in enumerate(rnd_clf.estimators_):\n",
    "# Extract feature importances for each label and store in a DataFrame\n",
    "    importances = []\n",
    "\n",
    "    for i, estimator in enumerate(rnd_clf.estimators_):\n",
    "        importances.append(estimator.feature_importances_)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    importances_df = pd.DataFrame(importances, columns=feature_names, index=label_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb00f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the DataFrame\n",
    "importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37f4dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming clf is your trained OneVsRestClassifier\n",
    "n_labels = len(rnd_clf.estimators_)\n",
    "n_features = X.shape[1]\n",
    "\n",
    "# Create a figure and a set of subplots\n",
    "fig, axes = plt.subplots(n_labels, 1, figsize=(10, n_labels * 5))\n",
    "\n",
    "# Plot feature importances for each label\n",
    "for i, estimator in enumerate(rnd_clf.estimators_):\n",
    "    axes[i].bar(range(n_features), estimator.feature_importances_)\n",
    "    axes[i].set_title(f'Feature importances for {label_names[i]}')\n",
    "    axes[i].set_xlabel('Features')\n",
    "    axes[i].set_ylabel('Importance')\n",
    "    axes[i].set_xticks(range(n_features))\n",
    "    axes[i].set_xticklabels(feature_names, rotation=90)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615fe7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train DecisionTree model for demo\n",
    "dt_clf_demo = DecisionTreeClassifier(max_depth=3, criterion=\"entropy\", random_state=random_state)\n",
    "dt_clf_demo.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2d7f4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "_ = tree.plot_tree(dt_clf_demo, feature_names=feature_cols, filled=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
